#
# use this script for merging the json files - generated by spider - github_dependents.py
#

import json
import os
import glob
import tqdm
# this directory
DIR = os.path.dirname(os.path.realpath(__file__))
TARGET_DIR = os.path.join(DIR, '..')
NAME = 'react'  # which will look for react.1.json, react.2.json, etc.

# select files with following pattern -> name.n.json (n for number)
files = glob.glob(os.path.join(TARGET_DIR, '{}.*.json'.format(NAME)))

# read each json files, check duplicate with key 'id', create a new unique set, export to json with name 'merged.json'
with open(os.path.join(TARGET_DIR, 'merged.json'), 'w') as outfile:
    # clear the file contents
    outfile.truncate()

    data = []
    try:
        for f in files:
            with open(f) as infile:
                data.extend(json.load(infile))
                infile.close()
    except Exception as e:
        print('Error reading file: {}'.format(f), e)

    # progress bar
    bar = tqdm.tqdm(total=len(data))

    # remove duplicate (do not use list(set(data)) or list(dict.fromkeys(data)))
    ids = []
    for d in data:
        if d['id'] not in ids:
            ids.append(d['id'])
            json.dump(d, outfile)
            outfile.write('\n')
        else:
            continue
        bar.update(1)

    print(
        f'Total: {len(ids)} from {len(data)}. removed {len(data) - len(ids)} duplicates.')
    print('Done')
    bar.close()
    outfile.close()
